# 语音处理流水线重构提案

## 变更ID
`refactor-voice-pipeline`

## 概述

参考 chat-companion-app 工程的成熟实现方案，对 ai-bookkeeping 当前语音处理流程进行深度重构，实现流畅自然的实时语音交互能力。

## 背景与动机

### 当前问题

1. **响应延迟高**：当前首字延迟 1.5-3.5 秒，用户体验不够流畅
2. **回声问题**：TTS播放时ASR可能识别到扬声器声音，造成误触发
3. **打断响应慢**：用户打断时响应不够及时
4. **流式处理不完善**：LLM生成、TTS合成、音频播放未能充分并行

### chat-companion-app 的成功经验

通过深入研究 chat-companion-app 工程，发现其核心优势：

| 指标 | chat-companion-app | ai-bookkeeping当前 |
|------|-------------------|-------------------|
| 首字延迟 | 400-600ms | 1500-3500ms |
| 打断响应 | 200ms | 500-1000ms |
| 回声防护 | 四层防护 | 单层（静音ASR） |
| 并发处理 | 三路并行流水线 | 串行为主 |

## 目标

1. **首字延迟 < 600ms**：从LLM开始生成到用户听到第一个字
2. **打断响应 < 300ms**：从检测到用户说话到TTS停止
3. **回声误识别率 < 1%**：四层回声防护机制
4. **支持流畅自然对话**：边说边听的全双工模式

## 核心变更

### 1. 流式TTS流水线

借鉴 chat-companion-app 的三路并行设计：

```
LLM流式生成 ──┬── 句子缓冲区 ──┬── TTS队列 ──┬── 音频播放
              │               │            │
           (并行)          (并行)       (并行)
```

- LLM边生成边检测句子边界
- 完整句子立即入队TTS合成
- TTS边合成边发送音频数据
- 客户端边接收边播放

### 2. 三层打断检测

| 层级 | 触发条件 | 响应时间 | 用途 |
|------|---------|---------|------|
| 第1层 | VAD + ASR中间结果 ≥4字 + 相似度<0.4 | ~200ms | 快速打断 |
| 第2层 | ASR中间结果 ≥8字 + 相似度<0.3 | ~500ms | 常规打断 |
| 第3层 | 完整句子 + 四层回声过滤 | ~1000ms | 可靠打断 |

### 3. 四层回声防护

1. **硬件级AEC**：使用 VOICE_COMMUNICATION 音源
2. **文本相似度**：计算ASR结果与当前TTS文本的相似度
3. **短句过滤**：忽略过短的ASR中间结果
4. **静默窗口**：TTS结束后等待回声消散

### 4. 响应ID机制

防止旧响应的完成事件影响新响应：

```dart
class ResponseTracker {
  int _currentResponseId = 0;

  int startNewResponse() => ++_currentResponseId;

  bool isCurrentResponse(int id) => id == _currentResponseId;
}
```

### 5. 会话状态机简化

从当前11个服务类简化为单一状态机：

```
IDLE ──▶ LISTENING ──▶ PROCESSING ──▶ SPEAKING ──▶ IDLE
  ▲                                       │
  └───────────── (用户打断) ──────────────┘
```

## 受影响模块

### 需要重构的文件

| 文件 | 变更类型 | 说明 |
|------|---------|------|
| `global_voice_assistant_manager.dart` | 重构 | 集成新流水线 |
| `streaming_tts_service.dart` | 重构 | 实现句子队列和流式播放 |
| `voice_recognition_engine.dart` | 修改 | 增强中间结果处理 |
| `tts_service.dart` | 修改 | 集成流水线模式 |

### 需要新建的文件

| 文件 | 说明 |
|------|------|
| `voice_pipeline_controller.dart` | 流水线控制器（核心） |
| `sentence_buffer.dart` | 句子缓冲与分割 |
| `tts_queue_worker.dart` | TTS队列工作器 |
| `echo_filter.dart` | 回声过滤器 |
| `barge_in_detector_v2.dart` | 三层打断检测器 |
| `response_tracker.dart` | 响应ID追踪器 |
| `similarity_calculator.dart` | 文本相似度计算 |

## 技术方案选择

### 方案A：纯客户端实现（推荐）

将流水线逻辑全部在Flutter客户端实现，复用现有服务：
- ASR：继续使用阿里云WebSocket流式识别
- TTS：继续使用流式TTS服务
- LLM：继续使用现有API调用

**优点**：改动范围可控，无需后端修改
**缺点**：客户端复杂度增加

### 方案B：增加后端WebSocket网关

类似 chat-companion-app 的架构，新增Python后端处理：
- 后端统一管理会话状态
- WebSocket全双工通信
- 后端做回声过滤和打断检测

**优点**：客户端简化，更接近参考实现
**缺点**：需要新增后端服务，部署复杂度增加

### 决策

采用**方案A（纯客户端实现）**，原因：
1. ai-bookkeeping已有成熟的后端架构
2. 避免增加运维复杂度
3. 核心优化（流水线并行）可在客户端实现

## 实施阶段

### 阶段1：流式TTS流水线（P0）
- 实现句子缓冲区和分割器
- 实现TTS队列工作器
- 集成到现有TTS服务
- 预期效果：首字延迟降至600ms以内

### 阶段2：三层打断检测（P0）
- 实现文本相似度计算
- 实现三层打断检测逻辑
- 集成到语音助手管理器
- 预期效果：打断响应降至300ms以内

### 阶段3：四层回声防护（P1）
- 增强硬件AEC配置
- 实现回声过滤器
- 添加静默窗口管理
- 预期效果：回声误识别率降至1%以内

### 阶段4：状态机简化与集成（P1）
- 实现统一状态机
- 实现响应ID追踪器
- 重构GlobalVoiceAssistantManager
- 预期效果：代码简化，维护性提升

## 验收标准

| 指标 | 目标值 | 测量方法 |
|------|--------|---------|
| 首字延迟 | < 600ms | 从ASR最终结果到TTS首音频 |
| 打断响应 | < 300ms | 从VAD检测到TTS停止 |
| 回声误识别率 | < 1% | TTS播放期间的误触发次数 |
| 连续对话成功率 | > 95% | 多轮对话完成率 |

## 风险与缓解

| 风险 | 影响 | 缓解措施 |
|------|------|---------|
| 流式TTS网络不稳定 | 播放卡顿 | 保留离线TTS降级方案 |
| 相似度计算性能 | CPU占用高 | 使用简化算法，限制计算频率 |
| 状态机重构影响功能 | 回归问题 | 充分测试，渐进式迁移 |

## 商业风险评估与依赖策略

### 与TEN-Agent对比及决策

经过对 [TEN Framework](https://github.com/TEN-framework/ten-framework) 的深入分析，虽然其技术方案先进，但**不建议直接集成**，原因如下：

#### 1. 许可证风险

| 组件 | 许可证 | 风险等级 |
|------|--------|---------|
| TEN Framework | Apache 2.0 **with additional restrictions** | ⚠️ 高 |
| TEN VAD | 需核实具体条款 | ⚠️ 中 |
| TEN Turn Detection | 需核实具体条款 | ⚠️ 中 |

**风险点**：TEN Framework 声明使用 Apache 2.0 许可证，但附带"额外限制条款"。在商业产品中使用前，需要法务详细审查具体限制内容，可能存在：
- 商业使用限制
- 衍生作品分发限制
- 归属要求
- 专利条款

**决策**：**不集成任何 TEN 组件**，自主实现核心功能。

#### 2. 外部依赖最小化原则

| 依赖类型 | 当前依赖 | 保持/移除 | 说明 |
|---------|---------|----------|------|
| ASR | 阿里云语音识别 | ✅ 保持 | 核心服务，已有商业协议 |
| TTS | 阿里云语音合成 | ✅ 保持 | 核心服务，已有商业协议 |
| LLM | 阿里云通义大模型 | ✅ 保持 | 核心服务，已有商业协议 |
| VAD | flutter_silero_vad | ✅ 保持 | MIT许可，纯本地，无网络依赖 |
| 音频播放 | just_audio | ✅ 保持 | MIT许可，Flutter标准库 |
| 外部框架 | TEN Framework | ❌ 不引入 | 许可证风险，增加依赖复杂度 |
| 外部模型 | TEN VAD/Turn Detection | ❌ 不引入 | 许可证风险，替代方案可行 |

#### 3. 资源消耗评估

本方案的资源消耗控制策略：

| 组件 | CPU影响 | 内存影响 | 优化措施 |
|------|---------|---------|---------|
| 相似度计算 | 中 | 低 | 节流控制（100ms间隔），简化算法 |
| 句子缓冲 | 低 | 低 | StringBuffer复用 |
| TTS队列 | 低 | 中 | 限制队列长度（≤5），及时清理临时文件 |
| 打断检测 | 低 | 低 | 复用现有VAD结果 |
| 回声过滤 | 低 | 低 | 简单字符串比较 |

**预估总体影响**：
- CPU增加：< 5%（主要来自相似度计算，已做节流）
- 内存增加：< 10MB（主要是音频缓冲区）
- 电池影响：可忽略（无新增后台服务）

#### 4. 自主实现 vs 引入外部依赖

| 功能 | TEN方案 | 我们的方案 | 差距 | 是否可接受 |
|------|---------|-----------|------|-----------|
| VAD延迟 | ~100ms | ~300-500ms | 200-400ms | ✅ 可接受 |
| 轮次检测 | 语义模型 | VAD静音检测 | 准确度略低 | ✅ 可接受 |
| 首字延迟 | <500ms | <600ms | 100ms | ✅ 可接受 |
| 打断响应 | <200ms | <300ms | 100ms | ✅ 可接受 |

**结论**：自主实现方案虽有差距，但完全能满足产品需求，且：
- 无许可证风险
- 无外部依赖风险
- 代码完全可控
- 后续优化空间大

### 未来优化路径（可选）

如果未来需要进一步优化，可考虑以下**无风险**方案：

1. **VAD优化**：调优 Silero VAD 参数，或评估其他 MIT/Apache 无限制许可的 VAD 方案
2. **轮次检测**：基于阿里云 NLP 服务实现语义轮次检测（复用已有商业协议）
3. **延迟优化**：优化网络层和音频缓冲策略

### 合规清单

实施前需确认：

- [x] 阿里云服务商业协议覆盖本项目使用场景
- [x] flutter_silero_vad MIT许可允许商业使用
- [x] just_audio MIT许可允许商业使用
- [x] 无需引入额外第三方服务
- [x] 无需引入额外开源组件（存疑许可证）

## 参考资料

- chat-companion-app 源码：`/Users/beihua/code/baiji/chat-companion-app/`
- chat-companion-app 设计文档：`docs/voice-chat-design.md`
- 当前架构分析：见 design.md

## 时间线

不提供具体时间估计，按阶段优先级实施。
