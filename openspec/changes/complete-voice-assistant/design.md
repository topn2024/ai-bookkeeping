# 语音智能助手技术设计文档

## 上下文

当前语音智能助手已具备完整的架构设计，包括：
- 多引擎ASR支持（阿里云在线 + Sherpa-ONNX离线）
- 多引擎TTS支持（系统TTS + 阿里云TTS）
- 完整的NLU引擎和意图路由
- 记账业务流程（添加/查询/修改/删除）

但核心API调用为模拟实现，需要实装真实服务。

### 约束
- 必须支持离线使用（记账核心功能）
- API密钥不能硬编码或暴露
- 需要兼容iOS和Android双平台
- 遵循现有的Riverpod状态管理模式

### 利益相关者
- 终端用户：需要流畅的语音交互体验
- 开发团队：需要清晰的API抽象和错误处理

---

## 目标 / 非目标

### 目标
- 实现生产级的语音识别和合成功能
- 提供无缝的在线/离线切换体验
- 实现安全的API密钥管理
- 完成所有已知的TODO项

### 非目标
- 不涉及NLU引擎的改进（当前实现已足够）
- 不涉及记账业务逻辑的修改
- 不实现多语言支持（当前仅支持中文）
- 不实现自定义唤醒词训练

---

## 决策

### 决策1：ASR实现方案

**选择：阿里云一句话识别API + WebSocket流式识别**

**理由：**
- 阿里云提供高准确率的中文识别（>95%）
- 支持金融领域热词定制
- 流式识别可提供实时反馈
- 已有账号和配置基础

**考虑的替代方案：**
| 方案 | 优点 | 缺点 | 结论 |
|------|------|------|------|
| 科大讯飞 | 准确率高 | SDK体积大，集成复杂 | 排除 |
| 百度语音 | 免费额度多 | 中文准确率略低 | 备选 |
| Google Speech | 国际标准 | 国内访问不稳定 | 排除 |
| 纯离线方案 | 无网络依赖 | 准确率和模型大小受限 | 作为降级方案 |

**API调用流程：**
```
用户说话 → 录音(record包) → 音频数据
    ↓
网络检测 → 在线? → 阿里云ASR (REST/WebSocket)
    ↓           ↓
    否          是
    ↓           ↓
Sherpa-ONNX ← 识别结果 → NLU处理
```

---

### 决策2：TTS实现方案

**选择：双引擎架构 - Flutter TTS（默认） + 阿里云TTS（高质量）**

**理由：**
- Flutter TTS利用系统TTS，无额外成本，低延迟
- 阿里云TTS提供更自然的语音，适合重要播报
- 用户可在设置中切换

**引擎选择策略：**
```dart
TTSEngine selectEngine(TTSContext context) {
  if (context.requireHighQuality) {
    return AlibabaCloudTTSEngine();
  }
  if (context.isOffline) {
    return FlutterTTSEngine();
  }
  return userPreference ?? FlutterTTSEngine();
}
```

---

### 决策3：唤醒词检测方案

**选择：Picovoice Porcupine**

**理由：**
- 支持离线运行，无网络依赖
- 提供Flutter SDK
- 支持自定义唤醒词
- 低功耗，适合后台运行

**考虑的替代方案：**
| 方案 | 优点 | 缺点 | 结论 |
|------|------|------|------|
| Snowboy | 开源免费 | 已停止维护 | 排除 |
| 阿里云唤醒 | 与ASR集成 | 需要网络 | 排除 |
| 自研方案 | 完全可控 | 开发成本高 | 未来考虑 |

**唤醒词：** "小白管家" 或 "记一笔"

---

### 决策4：API密钥管理方案

**选择：flutter_secure_storage + 服务端Token代理**

**架构：**
```
App启动 → 检查本地Token → 有效? → 直接使用
                           ↓
                          否
                           ↓
               请求后端Token代理服务
                           ↓
               后端使用AK/SK获取临时Token
                           ↓
               返回临时Token（有效期1小时）
                           ↓
               存储到flutter_secure_storage
```

**安全措施：**
- API密钥仅存储在服务端
- 客户端使用临时Token
- Token自动刷新机制
- 支持Token撤销

---

### 决策5：错误处理和降级策略

**错误分类和处理：**

| 错误类型 | 处理策略 | 用户提示 |
|----------|----------|----------|
| 网络不可用 | 切换离线ASR | "已切换到离线模式" |
| API限流 | 等待重试 + 离线降级 | "请稍后再试" |
| Token过期 | 自动刷新 | 无感知 |
| 识别失败 | 重试3次后提示 | "没听清，请再说一遍" |
| TTS失败 | 显示文字替代 | 静默降级 |

---

## 风险 / 权衡

### 风险1：阿里云服务不可用
- **影响：** 在线语音识别完全失效
- **概率：** 低（阿里云SLA 99.9%）
- **缓解：** 离线Sherpa-ONNX自动降级

### 风险2：唤醒词误触发
- **影响：** 用户体验受损
- **概率：** 中
- **缓解：** 可调灵敏度，默认设为中等

### 风险3：音频权限被拒
- **影响：** 语音功能完全不可用
- **概率：** 低
- **缓解：** 清晰的权限说明，优雅降级到文字输入

### 风险4：离线模型下载失败
- **影响：** 离线功能不可用
- **概率：** 中（网络环境复杂）
- **缓解：** 支持断点续传，提供模型预置选项

---

## 迁移计划

### 阶段1：基础设施（优先级1）
1. 实现Token代理服务（后端）
2. 实现flutter_secure_storage密钥管理
3. 替换ASR模拟实现为真实API调用
4. 替换TTS模拟实现为真实API调用

### 阶段2：功能完善（优先级2）
1. 集成Porcupine唤醒词检测
2. 实现确认流程UI
3. 完成命令历史显示
4. 完善错误处理

### 阶段3：优化测试（优先级3）
1. 性能优化（流缓冲、超时）
2. 单元测试和集成测试
3. 文档完善

### 回滚方案
- 每个阶段独立可回滚
- 保留模拟实现代码（通过配置开关）
- 灰度发布，逐步放量

---

## 待决问题

1. **唤醒词具体用词？** 建议"小白管家"，需产品确认
2. **阿里云TTS音色选择？** 当前支持6种，是否需要用户可选？
3. **离线模型预置还是按需下载？** 建议首次使用时下载
4. **Token代理服务部署位置？** 建议复用现有FastAPI后端

---

## 关键文件变更

| 文件 | 变更类型 | 说明 |
|------|----------|------|
| `voice_recognition_engine.dart` | 修改 | 实现真实ASR API |
| `tts_service.dart` | 修改 | 实现真实TTS API |
| `voice_wake_word_service.dart` | 修改 | 集成Porcupine |
| `voice_service_provider.dart` | 修改 | 完成确认流程 |
| `enhanced_voice_assistant_page.dart` | 修改 | 完成命令历史 |
| `voice_token_service.dart` | 新增 | Token管理服务 |
| `server/app/api/voice_token.py` | 新增 | Token代理端点 |
