# 语音智能体

## 新增需求

### 需求：输入预过滤器

输入预过滤器必须在意图识别前对用户输入进行快速分类，过滤无意义输入，减少不必要的 LLM 调用。

#### 场景：识别无意义噪音

**假设** 用户说了纯语气词或填充词
**当** 输入预过滤器处理该输入
**则** 必须返回 noise 分类
**并且** 系统必须静默忽略该输入，继续监听

**示例**：
- 输入："嗯" → noise → 静默
- 输入："啊" → noise → 静默
- 输入："那个..." → noise → 静默
- 输入："这个..." → noise → 静默

#### 场景：识别情绪表达

**假设** 用户发出重复字符或情感词
**当** 输入预过滤器处理该输入
**则** 必须返回 emotion 分类
**并且** 系统必须响应情感关怀

**示例**：
- 输入："啊啊啊啊啊" → emotion (frustration) → "深呼吸，慢慢来"
- 输入："呜呜呜" → emotion (negative) → "怎么了？"
- 输入："哈哈哈哈" → emotion (positive) → "看起来心情不错呀"

#### 场景：识别用户反馈

**假设** 用户说了确认、取消、犹豫或重复请求
**当** 输入预过滤器处理该输入
**则** 必须返回 feedback 分类
**并且** 系统必须根据反馈类型处理

**示例**：
- 输入："好的" → feedback (confirm)
- 输入："嗯嗯" → feedback (confirm)
- 输入："不要" → feedback (cancel) → "好的，取消了"
- 输入："算了" → feedback (cancel) → "好的，取消了"
- 输入："等等" → feedback (hesitate) → "好的，想好了告诉我"
- 输入："什么" → feedback (repeat) → 重复上一句

#### 场景：识别可处理输入

**假设** 用户输入不属于噪音、情绪或反馈
**当** 输入预过滤器处理该输入
**则** 必须返回 processable 分类
**并且** 输入必须进入意图识别流程

**示例**：
- 输入："记账35" → processable → 进入 SmartIntentRecognizer
- 输入："今天天气不错" → processable → 进入 SmartIntentRecognizer

---

### 需求：结果缓冲器

结果缓冲器必须暂存后台执行完成的操作结果，供时机判断器决定何时通知用户。

#### 场景：缓存执行结果

**假设** 后台执行完成一个操作
**当** 结果缓冲器接收到执行结果
**则** 结果必须被添加到缓冲区
**并且** 结果状态必须标记为 pending
**并且** 必须根据操作类型和金额计算优先级

**示例**：
- 删除操作 → 优先级 critical
- 金额 > 1000 → 优先级 critical
- 一般操作 → 优先级 normal

#### 场景：提供上下文摘要

**假设** 结果缓冲区中有待通知的结果
**当** 对话引擎请求上下文
**则** 结果缓冲器必须返回结果摘要
**并且** 摘要必须可用于 LLM 上下文

**示例**：
- 缓冲区有记账结果 → 摘要："【后台执行结果】\n- 记录了午餐35元"

#### 场景：清理过期结果

**假设** 结果在缓冲区停留超过 30 秒
**当** 清理机制运行
**则** 过期结果必须被移除
**并且** 必须释放相关资源

---

### 需求：时机判断器

时机判断器必须根据对话状态判断是否适合告知用户执行结果。

#### 场景：用户主动询问时立即通知

**假设** 用户询问操作结果
**并且** 有相关的执行结果
**当** 时机判断器评估当前状态
**则** 必须返回 immediate 决策
**并且** 系统必须立即告知结果

**示例**：
- 用户："记好了吗？" → immediate → "记好了，午餐35元"

#### 场景：用户沉默时通知

**假设** 用户停止说话超过 5 秒
**并且** 有待通知的执行结果
**当** 时机判断器评估当前状态
**则** 必须返回 onIdle 决策
**并且** 系统必须以主动话题方式告知结果

**示例**：
- 用户沉默 5 秒 → onIdle → "对了，刚才的午餐35已经记好了"

#### 场景：用户深度闲聊时延迟通知

**假设** 用户正在进行与业务无关的闲聊
**并且** 有待通知的执行结果
**当** 时机判断器评估当前状态
**则** 必须返回 defer 决策
**并且** 结果必须暂不通知用户

#### 场景：用户情绪负面时延迟通知

**假设** 检测到用户情绪为负面或沮丧
**并且** 有待通知的执行结果
**当** 时机判断器评估当前状态
**则** 必须返回 defer 决策
**并且** 结果必须暂不通知用户

---

### 需求：动态聚合窗口

动态聚合窗口必须实现滑动窗口机制，每次 ASR 返回时重置计时器，并根据语义分析动态调整等待时间。

#### 场景：ASR 返回时重置计时器

**假设** ASR 返回新的识别结果
**当** 动态聚合窗口处理该结果
**则** 必须取消旧计时器
**并且** 必须将结果加入缓冲区
**并且** 必须启动新计时器

#### 场景：检测到连接词延长等待

**假设** 用户输入包含连接词
**当** 动态聚合窗口计算等待时间
**则** 等待时间必须延长至 2000ms

**示例**：
- 输入："午餐35，还有..." → 延长等待 2000ms
- 输入："早餐20，另外..." → 延长等待 2000ms

#### 场景：检测到列举模式延长等待

**假设** 用户输入以逗号结尾且包含金额
**当** 动态聚合窗口计算等待时间
**则** 等待时间必须延长至 2000ms

**示例**：
- 输入："早餐15，午餐35，" → 延长等待 2000ms

#### 场景：完整交易缩短等待

**假设** 用户输入包含完整的交易信息（金额+分类）
**并且** VAD 检测到用户已停顿超过 500ms
**当** 动态聚合窗口计算等待时间
**则** 等待时间必须缩短至 800ms

**示例**：
- 输入："午餐花了35块钱" + 停顿 600ms → 缩短等待 800ms

#### 场景：默认等待时间

**假设** 无特殊语义特征
**当** 动态聚合窗口计算等待时间
**则** 必须使用默认等待时间 1200ms

#### 场景：最大等待时间兜底

**假设** 用户持续输入
**当** 累计等待时间超过 5000ms
**则** 必须强制触发聚合处理
**并且** 必须将缓冲区内容发送给智能引擎

---

## 修改需求

### 需求：智能引擎处理流程

智能引擎必须集成两层分类架构，实现执行层与对话层分离。

#### 场景：集成输入预过滤器

**假设** 用户语音输入到达智能引擎
**当** 智能引擎处理输入
**则** 必须首先经过输入预过滤器分类
**并且** 必须根据分类结果路由到相应处理流程
**并且** 只有 processable 类型才进入意图识别

#### 场景：操作异步执行

**假设** 意图识别结果为业务操作
**当** 智能引擎处理操作
**则** 必须立即返回简短确认（"好的"/"好的，N笔"）
**并且** 必须将操作提交到后台异步执行
**并且** 执行完成后必须将结果加入结果缓冲器

#### 场景：集成结果缓冲和时机判断

**假设** 后台操作执行完成
**当** 智能引擎收到执行结果
**则** 结果必须进入结果缓冲器
**并且** 必须调用时机判断器决定是否通知用户
**并且** 通知时机合适时必须通过 TTS 播放通知

#### 场景：闲聊时融入执行结果上下文

**假设** 用户正在闲聊
**并且** 结果缓冲器中有待通知结果
**当** 智能引擎生成闲聊回复
**则** 必须将结果摘要注入 LLM 上下文
**并且** 时机合适时必须自然融入执行结果
