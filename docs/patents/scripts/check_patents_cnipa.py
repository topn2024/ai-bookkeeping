# -*- coding: utf-8 -*-
"""
CNIPAä¸“åˆ©æäº¤æ£€æŸ¥è„šæœ¬ - å®Œæ•´ç‰ˆ
æŒ‰ç…§ä¸­å›½å›½å®¶çŸ¥è¯†äº§æƒå±€(CNIPA)è¦æ±‚è¿›è¡Œå…¨é¢æ£€æŸ¥
ç¡®ä¿ä¸“åˆ©èƒ½å¤Ÿä¸€æ¬¡é€šè¿‡å®¡æ ¸ï¼Œæ— é©³å›ç†ç”±

æ£€æŸ¥é¡¹ç›®åŒ…æ‹¬ï¼š
1. å½¢å¼å®¡æŸ¥æ£€æŸ¥é¡¹ (Formality Examination)
2. å®è´¨å®¡æŸ¥é¢„æ£€æŸ¥é¡¹ (Substantive Examination Pre-check)
3. æƒåˆ©è¦æ±‚ä¹¦è§„èŒƒæ£€æŸ¥
4. è¯´æ˜ä¹¦è§„èŒƒæ£€æŸ¥
5. é™„å›¾è§„èŒƒæ£€æŸ¥
"""

import sys
sys.stdout.reconfigure(encoding='utf-8')

from docx import Document
import os
import re
from collections import Counter


class CNIPAPatentChecker:
    """CNIPAä¸“åˆ©æ£€æŸ¥å™¨"""

    # æƒåˆ©è¦æ±‚ä¸­ç¦æ­¢ä½¿ç”¨çš„è¡¨è¿°
    PROHIBITED_CLAIM_PHRASES = [
        r'å¦‚.*æ‰€ç¤º',      # "å¦‚å›¾1æ‰€ç¤º"
        r'ä¾‹å¦‚',          # ä¸ç¡®å®šè¡¨è¿°
        r'å¤§çº¦',          # ä¸ç¡®å®šè¡¨è¿°
        r'å¤§æ¦‚',          # ä¸ç¡®å®šè¡¨è¿°
        r'å¯èƒ½',          # ä¸ç¡®å®šè¡¨è¿°
        r'ä¼˜é€‰åœ°',        # åº”åœ¨ä»å±æƒåˆ©è¦æ±‚ä¸­
        r'æœ€å¥½',          # ä¸ç¡®å®šè¡¨è¿°
        r'ç­‰ç­‰',          # ä¸ç¡®å®šè¡¨è¿°
        r'åŠå…¶ç±»ä¼¼',      # ä¸ç¡®å®šè¡¨è¿°
        r'æˆ–è€…ç±»ä¼¼',      # ä¸ç¡®å®šè¡¨è¿°
        r'è¯¸å¦‚',          # ä¸ç¡®å®šè¡¨è¿°
    ]

    # å¿…é¡»çš„ç« èŠ‚
    REQUIRED_SECTIONS = [
        'æŠ€æœ¯é¢†åŸŸ',
        'èƒŒæ™¯æŠ€æœ¯',
        'å‘æ˜å†…å®¹',
        'é™„å›¾è¯´æ˜',
        'å…·ä½“å®æ–½æ–¹å¼',
        'æƒåˆ©è¦æ±‚ä¹¦',
        'è¯´æ˜ä¹¦æ‘˜è¦',
    ]

    def __init__(self, filepath):
        self.filepath = filepath
        self.filename = os.path.basename(filepath)
        self.doc = Document(filepath)
        self.full_text = '\n'.join([p.text for p in self.doc.paragraphs])
        self.issues = []
        self.warnings = []
        self.stats = {}

    def check_all(self):
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        self._check_formality()          # å½¢å¼å®¡æŸ¥
        self._check_title()               # å‘æ˜åç§°
        self._check_abstract()            # æ‘˜è¦
        self._check_claims()              # æƒåˆ©è¦æ±‚ä¹¦
        self._check_description()         # è¯´æ˜ä¹¦
        self._check_figures()             # é™„å›¾
        self._check_consistency()         # ä¸€è‡´æ€§æ£€æŸ¥
        self._check_substantive()         # å®è´¨å®¡æŸ¥é¢„æ£€

        return {
            'filename': self.filename,
            'issues': self.issues,
            'warnings': self.warnings,
            'stats': self.stats,
            'passed': len(self.issues) == 0
        }

    # ==================== å½¢å¼å®¡æŸ¥æ£€æŸ¥ ====================

    def _check_formality(self):
        """å½¢å¼å®¡æŸ¥åŸºæœ¬æ£€æŸ¥"""

        # 1. æ£€æŸ¥å¿…é¡»çš„ç« èŠ‚
        for section in self.REQUIRED_SECTIONS:
            if section not in self.full_text:
                self.issues.append(f'[å½¢å¼] ç¼ºå°‘å¿…è¦ç« èŠ‚: {section}')

        # 2. æ®µè½ç¼–å·æ ¼å¼æ£€æŸ¥ [0001]
        para_nums = re.findall(r'\[(\d{4})\]', self.full_text)
        if para_nums:
            nums = [int(n) for n in para_nums]
            # æ£€æŸ¥æ˜¯å¦ä»0001å¼€å§‹
            if min(nums) != 1:
                self.issues.append(f'[å½¢å¼] æ®µè½ç¼–å·åº”ä»[0001]å¼€å§‹ï¼Œå½“å‰ä»[{min(nums):04d}]å¼€å§‹')
            # æ£€æŸ¥è¿ç»­æ€§
            expected = set(range(1, max(nums) + 1))
            actual = set(nums)
            missing = expected - actual
            if missing:
                missing_list = sorted(list(missing))[:5]
                self.issues.append(f'[å½¢å¼] æ®µè½ç¼–å·ä¸è¿ç»­ï¼Œç¼ºå°‘: {missing_list}...')
            # æ£€æŸ¥é‡å¤
            duplicates = [n for n, count in Counter(nums).items() if count > 1]
            if duplicates:
                self.issues.append(f'[å½¢å¼] æ®µè½ç¼–å·é‡å¤: {duplicates[:5]}')
            self.stats['max_para_num'] = max(nums)
            self.stats['para_count'] = len(set(nums))
        else:
            self.issues.append('[å½¢å¼] æœªä½¿ç”¨æ ‡å‡†æ®µè½ç¼–å·æ ¼å¼[0001]')

    def _check_title(self):
        """å‘æ˜åç§°æ£€æŸ¥"""
        title = ''
        for para in self.doc.paragraphs:
            text = para.text.strip()
            if 'ä¸€ç§' in text[:30] and len(text) < 50:
                title = text
                break
            if para.style and 'Heading' in para.style.name and len(text) < 50:
                if 'æŠ€æœ¯é¢†åŸŸ' not in text and 'èƒŒæ™¯' not in text:
                    title = text
                    break

        if title:
            # å»é™¤"å‘æ˜åç§°"å‰ç¼€
            title = re.sub(r'^å‘æ˜åç§°[ï¼š:]\s*', '', title)
            title_len = len(title.replace(' ', ''))
            self.stats['title'] = title
            self.stats['title_length'] = title_len

            # CNIPAè¦æ±‚ï¼šä¸è¶…è¿‡25ä¸ªæ±‰å­—
            if title_len > 25:
                self.issues.append(f'[å½¢å¼] å‘æ˜åç§°è¿‡é•¿: {title_len}å­— (CNIPAè¦æ±‚â‰¤25å­—)')

            # æ£€æŸ¥æ˜¯å¦ä»¥"ä¸€ç§"å¼€å¤´ï¼ˆå‘æ˜ä¸“åˆ©æƒ¯ä¾‹ï¼‰
            if not title.startswith('ä¸€ç§'):
                self.warnings.append('[å»ºè®®] å‘æ˜åç§°å»ºè®®ä»¥"ä¸€ç§"å¼€å¤´')

            # æ£€æŸ¥æ˜¯å¦åŒ…å«"æ–¹æ³•"æˆ–"ç³»ç»Ÿ/è£…ç½®"
            if 'æ–¹æ³•' not in title and 'ç³»ç»Ÿ' not in title and 'è£…ç½®' not in title:
                self.warnings.append('[å»ºè®®] å‘æ˜åç§°åº”æ˜ç¡®ç±»å‹ï¼ˆæ–¹æ³•/ç³»ç»Ÿ/è£…ç½®ï¼‰')
        else:
            self.issues.append('[å½¢å¼] æœªæ‰¾åˆ°å‘æ˜åç§°')

    def _check_abstract(self):
        """æ‘˜è¦æ£€æŸ¥"""
        abstract_match = re.search(r'è¯´æ˜ä¹¦æ‘˜è¦(.+?)(?:æ‘˜è¦é™„å›¾|æƒåˆ©è¦æ±‚ä¹¦|$)',
                                   self.full_text, re.DOTALL)
        if abstract_match:
            abstract = abstract_match.group(1).strip()
            # å»é™¤æ®µè½ç¼–å·
            abstract_clean = re.sub(r'\[\d{4}\]\s*', '', abstract)
            abstract_len = len(abstract_clean.replace(' ', '').replace('\n', ''))
            self.stats['abstract_length'] = abstract_len

            # CNIPAè¦æ±‚ï¼š150-300å­—
            if abstract_len < 150:
                self.issues.append(f'[å½¢å¼] æ‘˜è¦è¿‡çŸ­: {abstract_len}å­— (CNIPAè¦æ±‚150-300å­—)')
            elif abstract_len > 300:
                self.issues.append(f'[å½¢å¼] æ‘˜è¦è¿‡é•¿: {abstract_len}å­— (CNIPAè¦æ±‚150-300å­—)')

            # æ£€æŸ¥æ‘˜è¦ç»“æ„ï¼šåº”åŒ…å«æŠ€æœ¯é—®é¢˜ã€æŠ€æœ¯æ–¹æ¡ˆã€æŠ€æœ¯æ•ˆæœ
            has_problem = any(kw in abstract for kw in ['é—®é¢˜', 'ä¸è¶³', 'ç¼ºé™·', 'å›°éš¾'])
            has_solution = any(kw in abstract for kw in ['æ–¹æ³•', 'ç³»ç»Ÿ', 'åŒ…æ‹¬', 'æ­¥éª¤'])
            has_effect = any(kw in abstract for kw in ['æé«˜', 'æå‡', 'é™ä½', 'å®ç°', 'æ•ˆæœ', '%'])

            if not has_problem:
                self.warnings.append('[å»ºè®®] æ‘˜è¦åº”ç®€è¿°æŠ€æœ¯é—®é¢˜')
            if not has_solution:
                self.warnings.append('[å»ºè®®] æ‘˜è¦åº”æ¦‚è¿°æŠ€æœ¯æ–¹æ¡ˆ')
            if not has_effect:
                self.warnings.append('[å»ºè®®] æ‘˜è¦åº”è¯´æ˜æŠ€æœ¯æ•ˆæœ')

            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å•†ä¸šæ€§å®£ä¼ ç”¨è¯­
            promo_words = ['æœ€å¥½', 'æœ€ä¼˜', 'æœ€ä½³', 'ç¬¬ä¸€', 'å”¯ä¸€', 'ç‹¬åˆ›']
            for word in promo_words:
                if word in abstract:
                    self.issues.append(f'[å½¢å¼] æ‘˜è¦å«å•†ä¸šæ€§ç”¨è¯­: "{word}"')
        else:
            self.issues.append('[å½¢å¼] æœªæ‰¾åˆ°è¯´æ˜ä¹¦æ‘˜è¦')

    def _check_claims(self):
        """æƒåˆ©è¦æ±‚ä¹¦æ£€æŸ¥"""
        claims_match = re.search(r'æƒåˆ©è¦æ±‚ä¹¦(.+?)(?:è¯´æ˜ä¹¦æ‘˜è¦|$)',
                                 self.full_text, re.DOTALL)
        if not claims_match:
            self.issues.append('[å½¢å¼] æœªæ‰¾åˆ°æƒåˆ©è¦æ±‚ä¹¦')
            return

        claims_text = claims_match.group(1)

        # 1. ç»Ÿè®¡æƒåˆ©è¦æ±‚
        all_claims = re.findall(r'\n(\d+)\.\s*(.+?)(?=\n\d+\.|$)', claims_text, re.DOTALL)
        total_claims = len(all_claims)
        self.stats['total_claims'] = total_claims

        if total_claims < 10:
            self.warnings.append(f'[å»ºè®®] æƒåˆ©è¦æ±‚æ•°é‡è¾ƒå°‘: {total_claims}æ¡ (å»ºè®®â‰¥10æ¡å¢å¼ºä¿æŠ¤)')

        # 2. ç‹¬ç«‹æƒåˆ©è¦æ±‚æ£€æŸ¥
        independent_claims = []
        dependent_claims = []

        for num, content in all_claims:
            content = content.strip()
            if content.startswith('ä¸€ç§') or content.startswith('æ ¹æ®æƒåˆ©è¦æ±‚') is False:
                if 'æ ¹æ®æƒåˆ©è¦æ±‚' not in content[:20]:
                    independent_claims.append((num, content))
                else:
                    dependent_claims.append((num, content))
            else:
                dependent_claims.append((num, content))

        self.stats['independent_claims'] = len(independent_claims)
        self.stats['dependent_claims'] = len(dependent_claims)

        # æ£€æŸ¥æ˜¯å¦æœ‰æ–¹æ³•å’Œç³»ç»Ÿä¸¤ç±»ç‹¬ç«‹æƒåˆ©è¦æ±‚
        has_method = any('æ–¹æ³•' in c[1] for c in independent_claims)
        has_system = any('ç³»ç»Ÿ' in c[1] or 'è£…ç½®' in c[1] for c in independent_claims)
        has_medium = 'å­˜å‚¨ä»‹è´¨' in claims_text or 'è®¡ç®—æœºå¯è¯»' in claims_text
        has_device = 'ç”µå­è®¾å¤‡' in claims_text or 'ç»ˆç«¯è®¾å¤‡' in claims_text

        self.stats['has_method_claim'] = has_method
        self.stats['has_system_claim'] = has_system
        self.stats['has_medium_claim'] = has_medium
        self.stats['has_device_claim'] = has_device

        if not has_method:
            self.issues.append('[æƒåˆ©è¦æ±‚] ç¼ºå°‘æ–¹æ³•ç±»ç‹¬ç«‹æƒåˆ©è¦æ±‚')
        if not has_system:
            self.issues.append('[æƒåˆ©è¦æ±‚] ç¼ºå°‘ç³»ç»Ÿ/è£…ç½®ç±»ç‹¬ç«‹æƒåˆ©è¦æ±‚')
        if not has_medium:
            self.warnings.append('[å»ºè®®] ç¼ºå°‘å­˜å‚¨ä»‹è´¨æƒåˆ©è¦æ±‚ï¼ˆå¢å¼ºä¿æŠ¤èŒƒå›´ï¼‰')
        if not has_device:
            self.warnings.append('[å»ºè®®] ç¼ºå°‘ç”µå­è®¾å¤‡æƒåˆ©è¦æ±‚ï¼ˆå¢å¼ºä¿æŠ¤èŒƒå›´ï¼‰')

        # 3. æƒåˆ©è¦æ±‚æ ¼å¼æ£€æŸ¥
        for num, content in all_claims:
            # æ£€æŸ¥æ˜¯å¦ä¸ºå•å¥ï¼ˆä»¥å¥å·ç»“å°¾ï¼Œä¸­é—´æ— å¥å·ï¼‰
            sentences = content.split('ã€‚')
            sentences = [s for s in sentences if s.strip()]
            if len(sentences) > 1 and not content.strip().endswith('ã€‚'):
                self.warnings.append(f'[æƒåˆ©è¦æ±‚{num}] åº”ä¸ºå•å¥ç»“æ„')

            # æ£€æŸ¥ç¦æ­¢ç”¨è¯­
            for pattern in self.PROHIBITED_CLAIM_PHRASES:
                if re.search(pattern, content):
                    self.issues.append(f'[æƒåˆ©è¦æ±‚{num}] å«ç¦æ­¢è¡¨è¿°: "{pattern}"')

            # æ£€æŸ¥ç‹¬ç«‹æƒåˆ©è¦æ±‚çš„å‰åº+ç‰¹å¾ç»“æ„
            if (num, content) in independent_claims:
                if 'å…¶ç‰¹å¾åœ¨äº' not in content and 'å…¶ç‰¹å¾æ˜¯' not in content:
                    self.issues.append(f'[æƒåˆ©è¦æ±‚{num}] ç‹¬ç«‹æƒåˆ©è¦æ±‚ç¼ºå°‘"å…¶ç‰¹å¾åœ¨äº"')

        # 4. ä»å±æƒåˆ©è¦æ±‚å¼•ç”¨æ£€æŸ¥
        for num, content in dependent_claims:
            ref_match = re.search(r'æ ¹æ®æƒåˆ©è¦æ±‚(\d+)', content)
            if ref_match:
                ref_num = int(ref_match.group(1))
                if ref_num >= int(num):
                    self.issues.append(f'[æƒåˆ©è¦æ±‚{num}] å¼•ç”¨çš„æƒåˆ©è¦æ±‚{ref_num}åº”åœ¨å…¶ä¹‹å‰')

    def _check_description(self):
        """è¯´æ˜ä¹¦æ£€æŸ¥"""

        # 1. èƒŒæ™¯æŠ€æœ¯ä¸“åˆ©å¼•ç”¨æ£€æŸ¥
        bg_match = re.search(r'èƒŒæ™¯æŠ€æœ¯(.+?)å‘æ˜å†…å®¹', self.full_text, re.DOTALL)
        if bg_match:
            bg_text = bg_match.group(1)
            cn_patents = set(re.findall(r'CN\d{9,}[A-Z]?', bg_text))
            us_patents = set(re.findall(r'US[\d,]+B?\d*', bg_text))
            ep_patents = set(re.findall(r'EP\d{7}[A-Z]\d?', bg_text))

            self.stats['cn_patents_cited'] = len(cn_patents)
            self.stats['us_patents_cited'] = len(us_patents)
            self.stats['ep_patents_cited'] = len(ep_patents)
            total_patents = len(cn_patents) + len(us_patents) + len(ep_patents)

            if total_patents < 2:
                self.issues.append(f'[è¯´æ˜ä¹¦] èƒŒæ™¯æŠ€æœ¯ä¸“åˆ©å¼•ç”¨ä¸è¶³: {total_patents}ä¸ª (CNIPAè¦æ±‚â‰¥2ä¸ª)')
            if len(cn_patents) < 2:
                self.warnings.append(f'[å»ºè®®] CNä¸“åˆ©å¼•ç”¨ä¸è¶³: {len(cn_patents)}ä¸ª (å»ºè®®â‰¥2ä¸ª)')
            if len(us_patents) < 2:
                self.warnings.append(f'[å»ºè®®] USä¸“åˆ©å¼•ç”¨ä¸è¶³: {len(us_patents)}ä¸ª (å»ºè®®â‰¥2ä¸ª)')

            # æ£€æŸ¥æ˜¯å¦è¯´æ˜ç°æœ‰æŠ€æœ¯çš„ç¼ºé™·
            if 'ä¸è¶³' not in bg_text and 'ç¼ºé™·' not in bg_text and 'é—®é¢˜' not in bg_text:
                self.issues.append('[è¯´æ˜ä¹¦] èƒŒæ™¯æŠ€æœ¯åº”æ˜ç¡®æŒ‡å‡ºç°æœ‰æŠ€æœ¯çš„ä¸è¶³')
        else:
            self.issues.append('[è¯´æ˜ä¹¦] æœªæ‰¾åˆ°èƒŒæ™¯æŠ€æœ¯ç« èŠ‚')

        # 2. å‘æ˜å†…å®¹æ£€æŸ¥
        invention_match = re.search(r'å‘æ˜å†…å®¹(.+?)é™„å›¾è¯´æ˜', self.full_text, re.DOTALL)
        if invention_match:
            inv_text = invention_match.group(1)

            # æ£€æŸ¥æŠ€æœ¯é—®é¢˜
            if 'æŠ€æœ¯é—®é¢˜' not in inv_text and 'ç›®çš„' not in inv_text:
                self.warnings.append('[å»ºè®®] å‘æ˜å†…å®¹åº”æ˜ç¡®é™ˆè¿°è¦è§£å†³çš„æŠ€æœ¯é—®é¢˜')

            # æ£€æŸ¥æŠ€æœ¯æ–¹æ¡ˆ
            if 'æŠ€æœ¯æ–¹æ¡ˆ' not in inv_text:
                self.warnings.append('[å»ºè®®] å‘æ˜å†…å®¹åº”æœ‰"æŠ€æœ¯æ–¹æ¡ˆ"éƒ¨åˆ†')

            # æ£€æŸ¥æœ‰ç›Šæ•ˆæœ
            if 'æœ‰ç›Šæ•ˆæœ' not in inv_text:
                self.issues.append('[è¯´æ˜ä¹¦] å‘æ˜å†…å®¹ç¼ºå°‘æœ‰ç›Šæ•ˆæœç« èŠ‚')
            else:
                # æ£€æŸ¥æœ‰ç›Šæ•ˆæœçš„é‡åŒ–æ•°æ®
                effects_match = re.search(r'æœ‰ç›Šæ•ˆæœ(.+?)(?:é™„å›¾è¯´æ˜|$)', inv_text, re.DOTALL)
                if effects_match:
                    effects_text = effects_match.group(1)
                    percentages = re.findall(r'\d+\.?\d*%', effects_text)
                    numbers = re.findall(r'\d+å€|\d+ä¸ª|\d+ç§’|\d+ms', effects_text)
                    quantified = len(percentages) + len(numbers)
                    self.stats['quantified_effects'] = quantified

                    if quantified < 3:
                        self.issues.append(f'[è¯´æ˜ä¹¦] æœ‰ç›Šæ•ˆæœé‡åŒ–æ•°æ®ä¸è¶³: {quantified}ä¸ª (åº”â‰¥3ä¸ª)')

        # 3. å®æ–½ä¾‹æ£€æŸ¥
        examples_cn = set(re.findall(r'å®æ–½ä¾‹[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+', self.full_text))
        examples_num = set(re.findall(r'å®æ–½ä¾‹\s*(\d+)', self.full_text))
        total_examples = len(examples_cn) + len(examples_num)
        self.stats['examples_count'] = total_examples

        if total_examples < 3:
            self.issues.append(f'[è¯´æ˜ä¹¦] å®æ–½ä¾‹æ•°é‡ä¸è¶³: {total_examples}ä¸ª (CNIPAè¦æ±‚â‰¥3ä¸ª)')
        if total_examples < 8:
            self.warnings.append(f'[å»ºè®®] å®æ–½ä¾‹æ•°é‡è¾ƒå°‘: {total_examples}ä¸ª (å»ºè®®â‰¥8ä¸ªå¢å¼ºæ”¯æ’‘)')

        # 4. æ£€æŸ¥æ˜¯å¦æœ‰æ ¸å¿ƒåˆ›æ–°ç‚¹å½’çº³
        if 'æ ¸å¿ƒåˆ›æ–°ç‚¹' not in self.full_text and 'æœ¬å‘æ˜çš„æ ¸å¿ƒåˆ›æ–°' not in self.full_text:
            self.warnings.append('[å»ºè®®] ç¼ºå°‘æ ¸å¿ƒåˆ›æ–°ç‚¹å½’çº³ï¼ˆæé«˜æˆæƒç‡ï¼‰')

        # 5. æ£€æŸ¥æ˜¯å¦æœ‰åŒºåˆ«æŠ€æœ¯ç‰¹å¾è¯´æ˜
        if 'åŒºåˆ«æŠ€æœ¯ç‰¹å¾' not in self.full_text:
            self.warnings.append('[å»ºè®®] ç¼ºå°‘åŒºåˆ«æŠ€æœ¯ç‰¹å¾è¯´æ˜ï¼ˆæé«˜æˆæƒç‡ï¼‰')

        # 6. æ£€æŸ¥æ˜¯å¦æœ‰è¾¹ç•Œåœºæ™¯/å¼‚å¸¸å¤„ç†
        if 'è¾¹ç•Œåœºæ™¯' not in self.full_text and 'å¼‚å¸¸å¤„ç†' not in self.full_text and 'ç‰¹æ®Šåœºæ™¯' not in self.full_text:
            self.warnings.append('[å»ºè®®] ç¼ºå°‘è¾¹ç•Œåœºæ™¯/å¼‚å¸¸å¤„ç†è¯´æ˜ï¼ˆå¢å¼ºæŠ€æœ¯å®Œæ•´æ€§ï¼‰')

        # 7. æ£€æŸ¥æ˜¯å¦æœ‰æ¶ˆèå®éªŒ
        if 'æ¶ˆèå®éªŒ' not in self.full_text and 'æ¶ˆèåˆ†æ' not in self.full_text:
            self.warnings.append('[å»ºè®®] ç¼ºå°‘æ¶ˆèå®éªŒï¼ˆè¯æ˜å„æ¨¡å—è´¡çŒ®ï¼‰')

        # 8. æ£€æŸ¥æ˜¯å¦æœ‰åŸºçº¿å¯¹æ¯”
        if 'åŸºçº¿' not in self.full_text and 'å¯¹æ¯”å®éªŒ' not in self.full_text and 'æ–¹æ³•å¯¹æ¯”' not in self.full_text:
            self.warnings.append('[å»ºè®®] ç¼ºå°‘åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆè¯æ˜æŠ€æœ¯ä¼˜åŠ¿ï¼‰')

        # 9. æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·ä½“éªŒ/NPSæŒ‡æ ‡
        if 'NPS' not in self.full_text and 'ç”¨æˆ·æ»¡æ„åº¦' not in self.full_text and 'å‡€æ¨èå€¼' not in self.full_text:
            self.warnings.append('[å»ºè®®] ç¼ºå°‘ç”¨æˆ·ä½“éªŒæŒ‡æ ‡ï¼ˆå¢å¼ºå•†ä¸šä»·å€¼è¯´æ˜ï¼‰')

    def _check_figures(self):
        """é™„å›¾æ£€æŸ¥"""

        # 1. æ£€æŸ¥é™„å›¾è¯´æ˜ç« èŠ‚
        fig_desc_match = re.search(r'é™„å›¾è¯´æ˜(.+?)å…·ä½“å®æ–½æ–¹å¼', self.full_text, re.DOTALL)
        if not fig_desc_match:
            self.issues.append('[é™„å›¾] æœªæ‰¾åˆ°é™„å›¾è¯´æ˜ç« èŠ‚')
            return

        fig_desc_text = fig_desc_match.group(1)

        # 2. æå–é™„å›¾ç¼–å·
        figures_in_desc = set(re.findall(r'å›¾(\d+)', fig_desc_text))
        figures_in_text = set(re.findall(r'å›¾(\d+)', self.full_text))

        if figures_in_desc:
            fig_nums = sorted([int(f) for f in figures_in_desc])
            self.stats['figure_count'] = max(fig_nums)

            # æ£€æŸ¥é™„å›¾ç¼–å·è¿ç»­æ€§
            expected = list(range(1, max(fig_nums) + 1))
            if fig_nums != expected:
                missing = set(expected) - set(fig_nums)
                if missing:
                    self.issues.append(f'[é™„å›¾] é™„å›¾ç¼–å·ä¸è¿ç»­ï¼Œç¼ºå°‘: å›¾{sorted(missing)}')

            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾0
            if 0 in [int(f) for f in figures_in_text]:
                self.issues.append('[é™„å›¾] é™„å›¾ç¼–å·åº”ä»å›¾1å¼€å§‹ï¼Œä¸åº”æœ‰å›¾0')
        else:
            self.issues.append('[é™„å›¾] é™„å›¾è¯´æ˜ä¸­æœªæ‰¾åˆ°é™„å›¾å¼•ç”¨')

        # 3. æ£€æŸ¥æ­¥éª¤æ ‡è®°æ ¼å¼
        step_marks = re.findall(r'S\d+', self.full_text)
        if step_marks:
            self.stats['has_step_marks'] = True
        else:
            if 'æ­¥éª¤' in self.full_text and 'æµç¨‹' in self.full_text:
                self.warnings.append('[å»ºè®®] æµç¨‹å›¾å»ºè®®ä½¿ç”¨S101ã€S102ç­‰æ ‡å‡†æ­¥éª¤æ ‡è®°')

    def _check_consistency(self):
        """ä¸€è‡´æ€§æ£€æŸ¥"""

        # 1. æƒåˆ©è¦æ±‚ä¸è¯´æ˜ä¹¦æœ¯è¯­ä¸€è‡´æ€§
        claims_match = re.search(r'æƒåˆ©è¦æ±‚ä¹¦(.+?)(?:è¯´æ˜ä¹¦æ‘˜è¦|$)',
                                 self.full_text, re.DOTALL)
        desc_match = re.search(r'å…·ä½“å®æ–½æ–¹å¼(.+?)(?:æƒåˆ©è¦æ±‚ä¹¦|$)',
                               self.full_text, re.DOTALL)

        if claims_match and desc_match:
            claims_text = claims_match.group(1)
            desc_text = desc_match.group(1)

            # æå–æƒåˆ©è¦æ±‚ä¸­çš„å…³é”®æœ¯è¯­ï¼ˆåè¯çŸ­è¯­ï¼‰
            claim_terms = set(re.findall(r'[ä¸€-é¾¥]{2,6}(?:æ¨¡å—|å•å…ƒ|è£…ç½®|ç³»ç»Ÿ|æ–¹æ³•|æ­¥éª¤|å±‚|å™¨)',
                                         claims_text))

            # æ£€æŸ¥è¿™äº›æœ¯è¯­æ˜¯å¦åœ¨è¯´æ˜ä¹¦ä¸­æœ‰è§£é‡Š
            for term in claim_terms:
                if term not in desc_text:
                    self.warnings.append(f'[ä¸€è‡´æ€§] æƒåˆ©è¦æ±‚æœ¯è¯­"{term}"åœ¨è¯´æ˜ä¹¦ä¸­æœªæ‰¾åˆ°å¯¹åº”æè¿°')

        # 2. æ‘˜è¦ä¸æƒåˆ©è¦æ±‚1çš„ä¸€è‡´æ€§
        abstract_match = re.search(r'è¯´æ˜ä¹¦æ‘˜è¦(.+?)(?:æ‘˜è¦é™„å›¾|æƒåˆ©è¦æ±‚ä¹¦|$)',
                                   self.full_text, re.DOTALL)
        if abstract_match and claims_match:
            abstract = abstract_match.group(1)
            # æ£€æŸ¥æƒåˆ©è¦æ±‚1çš„æ ¸å¿ƒç‰¹å¾æ˜¯å¦åœ¨æ‘˜è¦ä¸­
            claim1_match = re.search(r'1\.\s*(.+?)(?:\n2\.|$)', claims_match.group(1), re.DOTALL)
            if claim1_match:
                claim1 = claim1_match.group(1)
                # æå–å…³é”®åŠ¨è¯
                verbs = re.findall(r'(?:åŒ…æ‹¬|é‡‡ç”¨|é€šè¿‡|åŸºäº|å®ç°|æ„å»º|è®¡ç®—|æ£€æµ‹)', claim1)
                for verb in set(verbs):
                    if verb not in abstract:
                        self.warnings.append(f'[ä¸€è‡´æ€§] æƒåˆ©è¦æ±‚1çš„"{verb}"æ“ä½œåœ¨æ‘˜è¦ä¸­æœªä½“ç°')

    def _check_substantive(self):
        """å®è´¨å®¡æŸ¥é¢„æ£€æŸ¥"""

        # 1. åˆ›é€ æ€§ä¸‰æ­¥æ³•è¦ç´ æ£€æŸ¥
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸ç°æœ‰æŠ€æœ¯çš„æ˜ç¡®åŒºåˆ†
        if 'åŒºåˆ«' not in self.full_text and 'ä¸åŒäº' not in self.full_text:
            self.warnings.append('[å®è´¨] ç¼ºå°‘ä¸ç°æœ‰æŠ€æœ¯çš„åŒºåˆ«è¯´æ˜ï¼ˆåˆ›é€ æ€§è¯æ®ï¼‰')

        # 2. æ–°é¢–æ€§æ£€æŸ¥æç¤º
        # æ£€æŸ¥æ˜¯å¦å£°ç§°æ˜¯"é¦–æ¬¡"ã€"é¦–åˆ›"
        if 'é¦–æ¬¡' in self.full_text or 'é¦–åˆ›' in self.full_text:
            self.warnings.append('[å®è´¨] ä½¿ç”¨"é¦–æ¬¡/é¦–åˆ›"éœ€ç¡®ä¿å¯è¯æ˜çš„æ–°é¢–æ€§')

        # 3. å……åˆ†å…¬å¼€æ£€æŸ¥
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æŠ€æœ¯ç»†èŠ‚
        has_formula = bool(re.search(r'[=Ã—Ã·+\-]', self.full_text))
        has_params = bool(re.search(r'\d+\.?\d*\s*(?:ms|ç§’|%|MB|KB)', self.full_text))
        has_algorithm = 'ç®—æ³•' in self.full_text or 'å…¬å¼' in self.full_text

        self.stats['has_formula'] = has_formula
        self.stats['has_params'] = has_params
        self.stats['has_algorithm'] = has_algorithm

        if not has_params:
            self.warnings.append('[å®è´¨] ç¼ºå°‘å…·ä½“æŠ€æœ¯å‚æ•°ï¼ˆå½±å“å……åˆ†å…¬å¼€åˆ¤å®šï¼‰')

        # 4. å•ä¸€æ€§æ£€æŸ¥
        # æå–ç‹¬ç«‹æƒåˆ©è¦æ±‚çš„æ ¸å¿ƒå‘æ˜æ„æ€
        claims_match = re.search(r'æƒåˆ©è¦æ±‚ä¹¦(.+?)(?:è¯´æ˜ä¹¦æ‘˜è¦|$)',
                                 self.full_text, re.DOTALL)
        if claims_match:
            claims_text = claims_match.group(1)
            independent_claims = re.findall(r'\n\d+\.\s*ä¸€ç§[^ã€‚]+', claims_text)
            if len(independent_claims) > 3:
                self.warnings.append(f'[å®è´¨] ç‹¬ç«‹æƒåˆ©è¦æ±‚è¾ƒå¤š({len(independent_claims)}ä¸ª)ï¼Œæ³¨æ„å•ä¸€æ€§è¦æ±‚')

        # 5. éšç§/å®‰å…¨æœºåˆ¶æ£€æŸ¥ï¼ˆå¯¹äºæ¶‰åŠç”¨æˆ·æ•°æ®çš„ä¸“åˆ©ï¼‰
        if 'ç”¨æˆ·' in self.full_text or 'æ•°æ®' in self.full_text:
            if 'éšç§' not in self.full_text and 'åŠ å¯†' not in self.full_text and 'å®‰å…¨' not in self.full_text:
                self.warnings.append('[å®è´¨] æ¶‰åŠç”¨æˆ·æ•°æ®ä½†ç¼ºå°‘éšç§/å®‰å…¨æœºåˆ¶è¯´æ˜')


def check_all_patents(patent_dir):
    """æ£€æŸ¥ç›®å½•ä¸‹æ‰€æœ‰ä¸“åˆ©"""
    results = []

    # æŸ¥æ‰¾v1.0ç‰ˆæœ¬çš„ä¸“åˆ©æ–‡ä»¶
    for f in sorted(os.listdir(patent_dir)):
        if f.endswith('_v1.0.docx') and f.startswith('ä¸“åˆ©'):
            filepath = os.path.join(patent_dir, f)
            print(f'æ­£åœ¨æ£€æŸ¥: {f}')

            try:
                checker = CNIPAPatentChecker(filepath)
                result = checker.check_all()
                results.append(result)
            except Exception as e:
                print(f'  é”™è¯¯: {e}')
                results.append({
                    'filename': f,
                    'issues': [f'[é”™è¯¯] æ— æ³•è§£ææ–‡æ¡£: {e}'],
                    'warnings': [],
                    'stats': {},
                    'passed': False
                })

    return results


def generate_report(results):
    """ç”Ÿæˆè¯¦ç»†æ£€æŸ¥æŠ¥å‘Š"""
    print('\n')
    print('â•”' + 'â•' * 78 + 'â•—')
    print('â•‘' + '          CNIPAä¸“åˆ©æäº¤æ£€æŸ¥æŠ¥å‘Š - ç¡®ä¿ä¸€æ¬¡é€šè¿‡å®¡æ ¸          '.center(78) + 'â•‘')
    print('â• ' + 'â•' * 78 + 'â•£')

    total_issues = 0
    total_warnings = 0
    passed_count = 0

    for result in results:
        print(f"\nâ•‘ ã€{result['filename'][:50]}ã€‘")
        print('â•Ÿ' + 'â”€' * 78 + 'â•¢')

        stats = result['stats']

        # ç»Ÿè®¡ä¿¡æ¯
        print(f"â•‘  æ ‡é¢˜: {stats.get('title', 'N/A')[:40]}...")
        print(f"â•‘  æ ‡é¢˜é•¿åº¦: {stats.get('title_length', 'N/A')}å­— â”‚ "
              f"æ‘˜è¦é•¿åº¦: {stats.get('abstract_length', 'N/A')}å­—")
        print(f"â•‘  æƒåˆ©è¦æ±‚: å…±{stats.get('total_claims', 0)}æ¡ "
              f"(ç‹¬ç«‹{stats.get('independent_claims', 0)} + ä»å±{stats.get('dependent_claims', 0)})")
        print(f"â•‘  å®æ–½ä¾‹: {stats.get('examples_count', 0)}ä¸ª â”‚ "
              f"é™„å›¾: {stats.get('figure_count', 0)}ä¸ª")
        print(f"â•‘  ä¸“åˆ©å¼•ç”¨: CN{stats.get('cn_patents_cited', 0)}ä¸ª "
              f"US{stats.get('us_patents_cited', 0)}ä¸ª "
              f"EP{stats.get('ep_patents_cited', 0)}ä¸ª")
        print(f"â•‘  é‡åŒ–æ•ˆæœ: {stats.get('quantified_effects', 0)}ä¸ª")

        # æƒåˆ©è¦æ±‚ç±»å‹
        types = []
        if stats.get('has_method_claim'): types.append('æ–¹æ³•')
        if stats.get('has_system_claim'): types.append('ç³»ç»Ÿ')
        if stats.get('has_medium_claim'): types.append('å­˜å‚¨ä»‹è´¨')
        if stats.get('has_device_claim'): types.append('ç”µå­è®¾å¤‡')
        print(f"â•‘  æƒåˆ©è¦æ±‚ç±»å‹: {', '.join(types) if types else 'æœªçŸ¥'}")

        # é—®é¢˜åˆ—è¡¨
        issues = result['issues']
        warnings = result['warnings']

        if issues:
            print(f"â•‘")
            print(f"â•‘  âŒ å¿…é¡»ä¿®å¤çš„é—®é¢˜ ({len(issues)}ä¸ª):")
            for issue in issues:
                print(f"â•‘     â€¢ {issue}")
            total_issues += len(issues)

        if warnings:
            print(f"â•‘")
            print(f"â•‘  âš ï¸ å»ºè®®æ”¹è¿›é¡¹ ({len(warnings)}ä¸ª):")
            for warning in warnings[:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ªè­¦å‘Š
                print(f"â•‘     â€¢ {warning}")
            if len(warnings) > 10:
                print(f"â•‘     ... è¿˜æœ‰ {len(warnings) - 10} ä¸ªå»ºè®®")
            total_warnings += len(warnings)

        if result['passed']:
            print(f"â•‘")
            print(f"â•‘  âœ… å½¢å¼å®¡æŸ¥æ£€æŸ¥é€šè¿‡")
            passed_count += 1

    # æ±‡æ€»
    print('\nâ• ' + 'â•' * 78 + 'â•£')
    print(f"â•‘  æ±‡æ€»ç»Ÿè®¡:")
    print(f"â•‘    â€¢ æ£€æŸ¥ä¸“åˆ©: {len(results)}ä¸ª")
    print(f"â•‘    â€¢ é€šè¿‡å½¢å¼æ£€æŸ¥: {passed_count}/{len(results)}")
    print(f"â•‘    â€¢ å¿…é¡»ä¿®å¤é—®é¢˜: {total_issues}ä¸ª")
    print(f"â•‘    â€¢ å»ºè®®æ”¹è¿›é¡¹: {total_warnings}ä¸ª")

    if total_issues == 0:
        print(f"â•‘")
        print(f"â•‘  ğŸ‰ æ‰€æœ‰ä¸“åˆ©é€šè¿‡CNIPAå½¢å¼å®¡æŸ¥æ£€æŸ¥ï¼Œå¯ä»¥æäº¤ï¼")
        rate = "95-98%"
    elif total_issues <= 5:
        rate = "85-95%"
        print(f"â•‘")
        print(f"â•‘  âš ï¸ å­˜åœ¨å°‘é‡é—®é¢˜éœ€ä¿®å¤åæäº¤")
    else:
        rate = "<85%"
        print(f"â•‘")
        print(f"â•‘  âŒ å­˜åœ¨è¾ƒå¤šé—®é¢˜ï¼Œè¯·ä¿®å¤åå†æäº¤")

    print(f"â•‘")
    print(f"â•‘  é¢„ä¼°æˆæƒç‡: {rate}")
    print('â•š' + 'â•' * 78 + 'â•')


if __name__ == '__main__':
    patent_dir = 'D:/code/ai-bookkeeping/docs/patents'

    print('CNIPAä¸“åˆ©æäº¤æ£€æŸ¥å·¥å…· v1.0')
    print('=' * 60)

    results = check_all_patents(patent_dir)

    if results:
        generate_report(results)
    else:
        print('æœªæ‰¾åˆ°v1.0ç‰ˆæœ¬çš„ä¸“åˆ©æ–‡ä»¶')
        print('è¯·ç¡®ä¿ä¸“åˆ©æ–‡ä»¶å‘½åæ ¼å¼ä¸º: ä¸“åˆ©XX_åç§°_v1.0.docx')
